# School of Computing &mdash; Year 4 Project Proposal Form


## SECTION A

|                     |                            |
|---------------------|----------------------------|
|Project Title:       | Text to Speech Reading Aid |
|Student 1 Name:      | Róisín O'Rourke            |
|Student 1 ID:        | 19360491                   |
|Student 2 Name:      | David Weir                 |
|Student 2 ID:        | 19433086                   |
|Project Supervisor:  | Paul Clarke                |


## SECTION B

### Introduction

> The system we propose is an Optical Character Recognition (OCR) text to speech reading aid. It will have the ability 
to scan printed and handwritten text, detect the text language, translate the text into a set sample of languages and 
then convert the text to mp3/pdf. The program will be written in Python and will use technologies such as tensorflow, 
tesseract, openCV, and Keras.

### Outline

> The project aims to help students and the visually impaired. The application will be able to scan uploaded pdf 
> documents and images containing printed or handwritten text. It will be capable of extracting the text from the 
> documents/files and then detect the language of the text. If the user wishes to translate the text from one language
> to another language they will be able to do so. Finally the system will create a mp3 file containing an audio reading
> of the text so that it can be listened to by the user or it will create a pdf version of the provided text (useful 
> for transforming written/printed notes to a student’s device).

### Background

> We came up with the idea for this project while brainstorming a system that would be multifunctional and have an 
> accessibility aspect to it. We wanted the project idea to have a practical use, we found the topic of OCR to be 
> interesting and we saw its potential for an interesting 4th year project.

### Achievements

> The program will be able to assist a wide variety of users with different needs and wants for the text to speech 
> abilities of the system.
We aim to provide a number of functions to the project, namely:
> * The program will be able to process images of printed and handwritten text and pdfs.
> * It will then detect the language of the processed text.
> * Using the detected language, the project will be able to translate the text into a number of different languages, if
> requested by the end user.
> * Finally, it will convert the text to pdf format and/or create a text-speech mp3 file so it can be listened to by
> the user. 
>
> The main expected users would be visually impaired people and students, however, the end product may be useful to many
> other user types including employees at work or the everyday person who wishes to convert their written lists or books
> to a pdf version accessible on their device.


### Justification

> The program will be able to assist the visually impaired by providing them with a tool to scan printed/written text 
> or pdfs and convert them to mp3 so that they can listen to them. Students may also find it useful to listen to their
> notes in audio format (e.g. when commuting) or to convert their written/printed notes to a pdf version on their
> devices.
> 
>In an educational setting, the system could allow visually impaired lecturers to scan written exam papers and correct 
> them by listening to them or it could assist visually impaired students in their studies. It will also be able to help
> students who wish to listen to their notes and study materials as they revise. The translation abilities of the system
> will also especially aid international students who can scan books/notes not provided in their home language and then 
> listen to them in their own language.
>
>This project could also be useful in the same ways in the workplace, as employees can have the same needs as students
> or to the everyday person at home.


### Programming language(s)

> The project will be developed in **Python** as it has a number of useful libraries available relevant to the project.
>
>The main programming language used for the project will be Python and we will be making use of several Python libraries
> to aid us in building the program.


### Programming tools / Tech stack

> * PyTesseract
> * Python
> * OpenCV
> * Keras
> * Tensorflow
> * Hugging face transformers


### Hardware

> **N/A** - No non-standard hardware will be required

### Learning Challenges

> * OCR model training (deep learning)
> * Handwriting recognition (Keras, Tensorflow, OpenCV)
> * Language Detection (language detection libraries)
> * Machine translation (Pytorch, transformer models)


### Breakdown of work

#### Róisín O'Rourke

> * Front end development
> * Language detection
> * Image / text conversion


#### David Weir

> * OCR model training
> * Machine translation
> * Model testing



